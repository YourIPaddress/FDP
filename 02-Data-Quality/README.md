
# ğŸ“˜ **DATA PREPROCESSING WORKBOOK**

This workbook introduces the most important steps in **Data Preprocessing**, using a simple and guided Python template.  
It is designed for learners from **non-coding backgrounds**, such as MBA students and faculty.

You will only need to **fill in the blanks (_____)** in two places.  
Everything else is already done for you.

---

# ğŸ” **1. What is Data Preprocessing?**

Data Preprocessing is the process of **cleaning, transforming, and preparing raw data** before building machine learning models.  
It makes the dataset:

- **Accurate** â†’ remove errors  
- **Complete** â†’ fill missing values  
- **Consistent** â†’ remove duplicates  
- **Machine-Readable** â†’ encode text labels  
- **Comparable** â†’ scale numerical values  

This step takes **70â€“80%** of the work in any analytics or ML project.

---

# ğŸ“‚ **2. What Data Are We Using?**

We are using the file:

```

sales_data.csv

````

This file contains business-style data such as:

- Month  
- Region  
- Product Category  
- Revenue  
- Units Sold  
- Marketing Spend  
- Monthly Sales (Target variable)

---

# ğŸ§¹ **3. Steps Covered in the Workbook**

---

## âœ… **Step 1: Load the Data**

```python
df = pd.read_csv("sales_data.csv")
````

This reads the dataset into a DataFrame so we can clean it.

---

## âœ… **Step 2: Handling Missing Values**

Real business data often has blanks.

We fill missing values in the **Revenue** column using the **mean**.

```python
df["Revenue"] = df["Revenue"].fillna( _____ )
```

ğŸ‘‰ **You must enter:**
`df["Revenue"].mean()`

This replaces missing entries with the average revenue.

---

## âœ… **Step 3: Removing Duplicates**

Duplicate rows are removed to improve quality.

```python
df = df.drop_duplicates()
```

---

## âœ… **Step 4: Encoding Categorical Data**

Machine learning models **cannot read text**, so we convert the `"Region"` column into **numbers** using One-Hot Encoding.

Example:

```
North â†’ 1 0 0 0  
South â†’ 0 1 0 0
```

The code:

```python
encoder = OneHotEncoder()
encoded = encoder.fit_transform(df[["Region"]]).toarray()

df[encoder.get_feature_names_out()] = encoded
df = df.drop(columns=["Region"])
```

This adds new columns:

```
Region_East  
Region_North  
Region_South  
Region_West
```

---

## âœ… **Step 5: Normalizing Numerical Features**

We scale `Revenue` so that all values become comparable.

```python
df["Revenue_scaled"] = scaler.fit_transform(df[["Revenue"]])
```

Scaling is needed because ML models perform better when large values (like revenue) do not overpower small values (like units sold).

---

## âœ… **Step 6: Splitting Data**

We divide the data into:

* **Training Set** â€” used to teach the model
* **Test Set** â€” used to check accuracy

You fill the blank:

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size= _____
)
```

ğŸ‘‰ **Recommended Entry:**
`0.2` (20% Test Data)

---

# ğŸ¯ **4. Your Tasks (Only 2 Blanks!)**

| Task                                  | Location | Expected Answer        |
| ------------------------------------- | -------- | ---------------------- |
| Fill missing Revenue values           | Step 2   | `df["Revenue"].mean()` |
| Choose test size for train-test split | Step 6   | `0.2`                  |

---

# ğŸ“Š **5. What Happens After Preprocessing?**

Your data becomes clean and ready for:

* Linear Regression
* Classification
* Forecasting
* Marketing analytics
* Sales prediction
* Customer segmentation

This workbook prepares you for **Model Building**, the next module.

---

# ğŸ‰ **6. Output**

Once everything is completed, you will see:

```
Preprocessing Complete!
```

Your dataset is now clean and machine-ready.

---

If you want, I can now generate:

âœ” A **Model Building Workbook (Regression)**
âœ” A **Classification Workbook (Yes/No prediction)**
âœ” A **Clustering Workbook (Customer Segmentation)**
âœ” A **README.md for each module**

Just tell me what you want next!

```

